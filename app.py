import asyncio
import io
import os
import logging
import zipfile
import tempfile
from typing import Dict, Any, List, Optional

from aiogram import Bot, Dispatcher, F
from aiogram.filters import CommandStart, Command
from aiogram.types import (
    Message, ContentType, InlineKeyboardMarkup, InlineKeyboardButton,
    CallbackQuery, BufferedInputFile
)
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from dotenv import load_dotenv

import requests
import replicate

# ===================== ENV =====================
load_dotenv()
BOT_TOKEN = os.environ["BOT_TOKEN"]
REPLICATE_API_TOKEN = os.environ["REPLICATE_API_TOKEN"]

# –ë—ç–∫–µ–Ω–¥—ã –∏ –º–æ–¥–µ–ª–∏: –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ ENV –≤ Railway
FLUX_MODEL = os.getenv("FLUX_MODEL", "black-forest-labs/flux-1.1-pro-ultra")
# –î–ª—è —Ñ–∏–Ω–µ—Ç—é–Ω–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Ç—Ä–µ–Ω–µ—Ä, –¥–∞—é—â–∏–π finetune_id)
FINETUNED_MODEL = os.getenv("FINETUNED_MODEL", "black-forest-labs/flux-1.1-pro-ultra-finetuned")

# Face-lock –º–æ–¥–µ–ª–∏ (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –Ω–∞ —Å–≤–æ–∏)
INSTANTID_MODEL = os.getenv("INSTANTID_MODEL", "grandlineai/instant-id-photorealistic")
IPADAPTER_MODEL = os.getenv("IPADAPTER_MODEL", "lucataco/ip-adapter-faceid")

# –¢—Ä–µ–Ω–µ—Ä LoRA/finetune –Ω–∞ Replicate (–ó–ê–î–ê–ô –°–ê–ú!)
# –û—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º, –µ—Å–ª–∏ —Ç—Ä–µ–Ω–µ—Ä –µ—â—ë –Ω–µ –≤—ã–±—Ä–∞–Ω ‚Äî /finish –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–æ–æ–±—â–∏—Ç –æ–± —ç—Ç–æ–º
LORA_TRAINER_MODEL = os.getenv("LORA_TRAINER_MODEL", "")  # –ø—Ä–∏–º–µ—Ä: "black-forest-labs/flux-pro-trainer"

# –ö–∞–∫ –ø–æ–¥–º–µ—à–∏–≤–∞–µ—Ç—Å—è LoRA –≤ –æ–±—ã—á–Ω—ã–π FLUX (–µ—Å–ª–∏ —Ç—Ä–µ–Ω–µ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL –≤–µ—Å–æ–≤)
LORA_APPLY_PARAM = os.getenv("LORA_APPLY_PARAM", "lora_urls")  # –∏–ª–∏ "adapters" –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
LORA_SCALE_DEFAULT = float(os.getenv("LORA_SCALE_DEFAULT", "0.7"))

# ===================== SDK / BOT =====================
replicate_client = replicate.Client(api_token=REPLICATE_API_TOKEN)
bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()
logging.basicConfig(level=logging.INFO)

# ===================== IN-MEMORY STATE (–Ω–∞ –ø—Ä–æ–¥–µ –≤—ã–Ω–µ—Å–∏ –≤ Redis/DB) =====================
USER_LAST_PHOTO: Dict[int, bytes] = {}
USER_LAST_PROMPT: Dict[int, str] = {}
USER_BACKEND: Dict[int, str] = {}   # "instantid" | "ipadapter" | "flux"
USER_TRAIN_SET: Dict[int, List[bytes]] = {}
# –í–∞—Ä–∏–∞–Ω—Ç 1 (–±–µ–∑ finetune_id): {"url": str|None, "enabled": bool, "status": "none|training|ready|failed"}
# –í–∞—Ä–∏–∞–Ω—Ç 2 (—Å finetune_id):   {"finetune_id": str|None, "trigger": str|None, "enabled": bool, "status": "..."}
USER_LORA: Dict[int, Dict[str, Any]] = {}

# ===================== STYLES (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä) =====================
STYLES: Dict[str, Dict[str, str]] = {
    "real_raw": {"prompt": "ultra realistic headshot, RAW photo look, soft studio light, skin texture, natural colors, detailed eyes, shallow depth of field, 85mm lens"},
    "cinematic": {"prompt": "cinematic portrait, dramatic rim light, volumetric light, film grain, teal and orange color grading, background bokeh"},
    "cyberpunk": {"prompt": "cyberpunk neon portrait, rainy night, neon reflections, holographic HUD, high detail, futuristic vibes"},
    "anime": {"prompt": "masterpiece, best quality, high-quality anime portrait, detailed irises, clean lineart, soft shading, vibrant palette"},
    "pixar3d": {"prompt": "3d stylized pixar-like portrait, subsurface scattering, soft key light, studio render, highly detailed, glossy skin"},
    "vogue": {"prompt": "editorial fashion portrait, glossy lighting, beauty retouch, professional studio, elegant styling, magazine cover look"},
    "lofi_film": {"prompt": "lofi film portrait, kodak portra vibes, soft highlights, muted tones, nostalgic mood, film grain subtle"},
    "fantasy_elf": {"prompt": "fantasy elf portrait, ethereal rim light, delicate face, intricate accessories, mystical forest atmosphere"},
    "comic": {"prompt": "comic book portrait, bold ink lines, halftone shading, high contrast, dynamic pose, graphic look"},
    "pop_art": {"prompt": "pop art portrait, bold colors, graphic shapes, clean background, posterized look, contemporary design"},
    "bw_classic": {"prompt": "black and white classic portrait, strong contrast, soft key light, timeless look, studio photography"},
    "poster_graphic": {"prompt": "graphic poster style portrait, minimal layout, strong typography accents, bold composition, color blocking"},
    "studio_beauty": {"prompt": "beauty studio portrait, clamshell lighting, glossy skin, catchlights in the eyes, editorial makeup"},
    "noir": {"prompt": "film noir portrait, hard light, dramatic shadows, moody atmosphere, vintage cinematic look"},
    "baroque": {"prompt": "baroque oil painting portrait, chiaroscuro, rich textures, ornate details, museum quality"}
}

def styles_keyboard() -> InlineKeyboardMarkup:
    buttons, row = [], []
    for k in STYLES.keys():
        row.append(InlineKeyboardButton(text=k, callback_data=f"style:{k}"))
        if len(row) == 3:
            buttons.append(row); row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(inline_keyboard=buttons)

def modes_keyboard() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="üîí InstantID (1 —Ñ–æ—Ç–æ)", callback_data="mode:instantid"),
            InlineKeyboardButton(text="üîí IP-Adapter", callback_data="mode:ipadapter"),
            InlineKeyboardButton(text="üé® FLUX", callback_data="mode:flux"),
        ]
    ])

# ===================== HELPERS =====================
def _to_bytes_from_output(output: Any) -> bytes:
    """Replicate –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å url, —Å–ø–∏—Å–æ–∫, file-like. –ü—Ä–∏–≤–æ–¥–∏–º –∫ bytes."""
    obj = output[0] if isinstance(output, list) else output
    if hasattr(obj, "read"):
        return obj.read()
    if isinstance(obj, str) and obj.startswith("http"):
        r = requests.get(obj, timeout=60)
        r.raise_for_status()
        return r.content
    raise RuntimeError("Unknown output type from Replicate model")

async def _download_as_bytes(message: Message) -> bytes:
    """–°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (photo/document) –∫–∞–∫ bytes; –¥–ª—è document –¢–µ–ª–µ–≥–∞ –Ω–µ —Å–∂–∏–º–∞–µ—Ç."""
    buf = io.BytesIO()
    if message.content_type == ContentType.PHOTO:
        await bot.download(message.photo[-1], destination=buf)
    elif message.content_type == ContentType.DOCUMENT:
        await bot.download(message.document, destination=buf)
    else:
        raise ValueError("Unsupported content type for image download")
    buf.seek(0)
    return buf.getvalue()

# ===================== GENERATORS =====================
def generate_with_flux(image_bytes: bytes, prompt: str, lora_url: Optional[str] = None, lora_scale: float = LORA_SCALE_DEFAULT) -> bytes:
    image_file = io.BytesIO(image_bytes); image_file.name = "input.jpg"
    inputs: Dict[str, Any] = {
        "prompt": prompt,
        "image_prompt": image_file,
        "image_prompt_strength": 0.7,   # —É—Å–∏–ª–∏–ª–∏ –≤–ª–∏—è–Ω–∏–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ (–¥–ª—è —Å—Ö–æ–¥—Å—Ç–≤–∞)
        "raw": True,
        "aspect_ratio": "1:1",
    }
    # –ï—Å–ª–∏ –µ—Å—Ç—å LoRA-URL (–º–æ–¥–µ–ª–∏, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–µ –ø–æ–¥–º–µ—à–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤)
    if lora_url:
        if LORA_APPLY_PARAM == "lora_urls":
            inputs["lora_urls"] = [lora_url]
            inputs["lora_scales"] = [lora_scale]  # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
        elif LORA_APPLY_PARAM == "adapters":
            inputs["adapters"] = [{"path": lora_url, "weight": lora_scale}]
        else:
            inputs["lora_urls"] = [lora_url]

    out = replicate.run(FLUX_MODEL, input=inputs)
    return _to_bytes_from_output(out)

def generate_with_flux_finetuned(prompt: str, finetune_id: str, finetune_strength: float = 1.0) -> bytes:
    """–ò–Ω—Ñ–µ—Ä–µ–Ω—Å –ø–æ finetune_id (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –º–æ–¥–µ–ª—å –≤–∏–¥–∞ *-finetuned)."""
    out = replicate.run(
        FINETUNED_MODEL,
        input={
            "prompt": prompt,
            "finetune_id": finetune_id,           # –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
            "finetune_strength": finetune_strength,  # 0..2 (–≤–∞—Ä—å–∏—Ä—É–π 0.7‚Äì1.2)
            "raw": True,
            "aspect_ratio": "1:1",
        }
    )
    return _to_bytes_from_output(out)

def generate_with_instantid(face_bytes: bytes, prompt: str) -> bytes:
    face = io.BytesIO(face_bytes); face.name = "face.jpg"

    inputs = {
        "image": face,                      # –≤–º–µ—Å—Ç–æ URL –ø–æ–¥–∞—ë–º —Ñ–∞–π–ª
        "prompt": prompt,
        "controlnet_conditioning_scale": 0.6,   # –∫–∞–∫ –≤ —Ç–≤–æ—ë–º –ø—Ä–∏–º–µ—Ä–µ
        # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏: "num_inference_steps": 28, "guidance_scale": 3.5, "seed": 0
    }

    # –µ—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å _replicate_run(ref, inputs, version), –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ:
    out = _replicate_run(INSTANTID_MODEL, inputs, version=INSTANTID_VERSION)

    # —Ñ–∞–π–ª/URL ‚Üí bytes (—É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å —Ö–µ–ª–ø–µ—Ä)
    return _to_bytes_from_output(out)


def generate_with_ipadapter(face_bytes: bytes, prompt: str) -> bytes:
    face = io.BytesIO(face_bytes); face.name = "face.jpg"
    # –£ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä—Ç–æ–≤ –ø–æ–ª—è –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è ‚Äî –ø—Ä–æ–±—É–µ–º 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞
    try:
        out = replicate.run(IPADAPTER_MODEL, input={"face_image": face, "prompt": prompt})
    except Exception:
        out = replicate.run(IPADAPTER_MODEL, input={"image": face, "prompt": prompt})
    return _to_bytes_from_output(out)

# ===================== LORA / FINETUNE TRAINING =====================
def _train_flux_finetune_sync(image_bytes_list: List[bytes], caption_prefix: str) -> str:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–µ—Ä–∞ –Ω–∞ Replicate.
    –í–ê–ñ–ù–û: –ø–æ–ª—è inputs –∑–∞–≤–∏—Å—è—Ç –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏-—Ç—Ä–µ–Ω–µ—Ä–∞. –ù–∏–∂–µ –ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã—Ö.
    –û—Ç–∫—Ä–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–≤–æ–µ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞ –Ω–∞ Replicate –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–¥–≥–æ–Ω–∏ –∏–º–µ–Ω–∞ –ø–æ–ª–µ–π.
    """
    # –°–æ–±–∏—Ä–∞–µ–º ZIP —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏
    with tempfile.NamedTemporaryFile(suffix=".zip", delete=False) as tmp:
        with zipfile.ZipFile(tmp, "w") as zf:
            for i, b in enumerate(image_bytes_list):
                zf.writestr(f"img_{i:02d}.jpg", b)
        tmp.flush()
        zip_path = tmp.name

    if not LORA_TRAINER_MODEL:
        raise RuntimeError("LORA_TRAINER_MODEL is not set. Configure a trainer model on Replicate first.")

    # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–∑–≤–∞—Ç—å —Ç—Ä–µ–Ω–µ—Ä —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
    trainer_inputs_variants = [
        {"input_images": open(zip_path, "rb"), "caption_prefix": caption_prefix},
        {"images_zip": open(zip_path, "rb"), "caption_prefix": caption_prefix},
        {"dataset": open(zip_path, "rb"), "caption_prefix": caption_prefix},
        {"images": open(zip_path, "rb"), "caption_prefix": caption_prefix},
    ]

    last_exc = None
    for inp in trainer_inputs_variants:
        try:
            out = replicate.run(LORA_TRAINER_MODEL, input=inp)
            # –û–∂–∏–¥–∞–µ–º –ª–∏–±–æ finetune_id (str), –ª–∏–±–æ dict c –∫–ª—é—á–æ–º
            if isinstance(out, str):
                return out
            if isinstance(out, dict):
                # –ù–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ç—Ä–µ–Ω–µ—Ä–∞—Ö –∫–ª—é—á –º–æ–∂–µ—Ç –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É
                for k in ("finetune_id", "id", "model_id"):
                    if k in out and isinstance(out[k], str):
                        return out[k]
            if isinstance(out, list) and out and isinstance(out[0], str):
                return out[0]
        except Exception as e:
            last_exc = e
            continue

    raise RuntimeError(f"Trainer call failed / unexpected output. Last error: {last_exc}")

async def _train_and_notify(uid: int, imgs: List[bytes]):
    """–§–æ–Ω–æ–≤—ã–µ –æ–±—É—á–µ–Ω–∏–µ finetune, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –±–æ—Ç–∞."""
    trigger = f"user_{uid}"  # –±—É–¥–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –≤ prompt
    loop = asyncio.get_running_loop()
    try:
        finetune_id = await loop.run_in_executor(None, lambda: _train_flux_finetune_sync(imgs, trigger))
        USER_LORA[uid] = {"finetune_id": finetune_id, "trigger": trigger, "enabled": True, "status": "ready"}
        await bot.send_message(uid, f"‚úÖ –§–∏–Ω–µ—Ç—é–Ω –≥–æ—Ç–æ–≤ –∏ –≤–∫–ª—é—á—ë–Ω!\nID: <code>{finetune_id}</code>\n–†–µ–∂–∏–º: FLUX ‚Üí /styles ‚Üí —Å—Ç–∏–ª—å.")
    except Exception as e:
        USER_LORA[uid] = {"finetune_id": None, "trigger": None, "enabled": False, "status": "failed"}
        logging.exception("LoRA/finetune training failed")
        await bot.send_message(uid, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏: {e}\n–ü—Ä–æ–≤–µ—Ä—å —Ç—Ä–µ–Ω–µ—Ä (LORA_TRAINER_MODEL) –∏ —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–æ–≤.")

# ===================== HANDLERS =====================
@dp.message(CommandStart())
async def start(m: Message):
    uid = m.from_user.id
    USER_BACKEND.setdefault(uid, "instantid")
    USER_LORA.setdefault(uid, {"finetune_id": None, "trigger": None, "enabled": False, "status": "none"})
    await m.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ AI-–∞–≤–∞—Ç–∞—Ä-–±–æ—Ç.\n\n"
        "1) –ü—Ä–∏—à–ª–∏ —Å–≤–æ—ë —Ñ–æ—Ç–æ (–ª—É—á—à–µ –∫–∞–∫ <b>—Ñ–∞–π–ª</b> ‚Äî –±–µ–∑ —Å–∂–∞—Ç–∏—è).\n"
        "2) /styles ‚Äî –≤—ã–±–µ—Ä–∏ —Å—Ç–∏–ª—å.\n"
        "3) /modes ‚Äî —Ä–µ–∂–∏–º: <b>InstantID</b> / <b>IP-Adapter</b> / <b>FLUX</b>.\n"
        "4) /train ‚Äî —Å–æ–±—Ä–∞—Ç—å 6‚Äì12 —Ñ–æ—Ç–æ (—Ñ–∞–π–ª—ã) –¥–ª—è —Ñ–∏–Ω–µ—Ç—é–Ω–∞ ‚Üí /finish.\n"
        "5) /lora_on, /lora_off ‚Äî –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å LoRA (–µ—Å–ª–∏ –µ—Å—Ç—å finetune).\n"
        "6) /set_finetune &lt;finetune_id&gt; ‚Äî –≤—Ä—É—á–Ω—É—é —É–∫–∞–∑–∞—Ç—å finetune_id (–µ—Å–ª–∏ —É–∂–µ –æ–±—É—á–µ–Ω).\n\n"
        f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: <b>{USER_BACKEND[uid]}</b>"
    )

@dp.message(Command("styles"))
async def list_styles(m: Message):
    await m.answer("–í—ã–±–µ—Ä–∏ —Å—Ç–∏–ª—å –Ω–∏–∂–µ üëá", reply_markup=styles_keyboard())

@dp.message(Command("modes"))
async def modes(m: Message):
    await m.answer("–í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: InstantID –¥–ª—è —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏–∑ 1 —Ñ–æ—Ç–æ.", reply_markup=modes_keyboard())

@dp.callback_query(F.data.startswith("mode:"))
async def switch_mode(cq: CallbackQuery):
    uid = cq.from_user.id
    mode = cq.data.split(":", 1)[1]
    USER_BACKEND[uid] = mode
    await cq.message.answer(f"–†–µ–∂–∏–º –ø–µ—Ä–µ–∫–ª—é—á—ë–Ω –Ω–∞: <b>{mode}</b>")
    await cq.answer()

@dp.message(F.content_type == ContentType.PHOTO)
async def on_photo(m: Message):
    b = await _download_as_bytes(m)
    USER_LAST_PHOTO[m.from_user.id] = b
    USER_LAST_PROMPT[m.from_user.id] = (m.caption or "").strip()
    await m.answer("üì∏ –§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ. –ù–∞–∂–º–∏ /styles –∏ –≤—ã–±–µ—Ä–∏ —Å—Ç–∏–ª—å.")

@dp.message(F.content_type == ContentType.DOCUMENT, F.document.mime_type.in_({"image/jpeg","image/png"}))
async def on_image_doc(m: Message):
    b = await _download_as_bytes(m)  # –±–µ–∑ —Å–∂–∞—Ç–∏—è
    USER_LAST_PHOTO[m.from_user.id] = b
    USER_LAST_PROMPT[m.from_user.id] = (m.caption or "").strip()
    await m.answer("üìé –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –±–µ–∑ —Å–∂–∞—Ç–∏—è. –ù–∞–∂–º–∏ /styles –∏ –≤—ã–±–µ—Ä–∏ —Å—Ç–∏–ª—å.")

@dp.callback_query(F.data.startswith("style:"))
async def on_style_click(cq: CallbackQuery):
    uid = cq.from_user.id
    key = cq.data.split(":", 1)[1]
    if uid not in USER_LAST_PHOTO:
        await cq.message.answer("–°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏—à–ª–∏ —Å–≤–æ—ë —Ñ–æ—Ç–æ.")
        return await cq.answer()
    if key not in STYLES:
        await cq.message.answer("–¢–∞–∫–æ–≥–æ —Å—Ç–∏–ª—è –Ω–µ—Ç. –ü–æ—Å–º–æ—Ç—Ä–∏ /styles")
        return await cq.answer()

    base_prompt = STYLES[key]["prompt"]
    extra = USER_LAST_PROMPT.get(uid, "")
    prompt = (base_prompt + (f", {extra}" if extra else "")).strip()

    info = USER_LORA.get(uid)
    backend = USER_BACKEND.get(uid, "instantid")

    await cq.message.answer(f"üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é: <b>{key}</b> ‚Ä¶ 10‚Äì40 —Å–µ–∫.")
    await cq.answer()

    try:
        # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω FLUX –∏ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–π finetune_id ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ (TEXT‚ÜíIMG)
        if backend == "flux" and info and info.get("enabled") and info.get("status") == "ready" and info.get("finetune_id"):
            trigger = info.get("trigger") or ""
            prompt_ft = (f"{trigger}, {prompt}").strip(", ")
            img_bytes = generate_with_flux_finetuned(prompt_ft, info["finetune_id"], finetune_strength=0.9)
        else:
            # –ò–Ω–∞—á–µ ‚Äî face-lock –∏–ª–∏ –æ–±—ã—á–Ω–∞—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏—è FLUX —Å image_prompt
            face_bytes = USER_LAST_PHOTO[uid]
            if backend == "instantid":
                img_bytes = generate_with_instantid(face_bytes, prompt)
            elif backend == "ipadapter":
                img_bytes = generate_with_ipadapter(face_bytes, prompt)
            else:  # –æ–±—ã—á–Ω—ã–π FLUX
                # –µ—Å–ª–∏ —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å LoRA-URL –≤–º–µ—Å—Ç–æ finetune_id, –º–æ–∂–Ω–æ –ø–æ–¥–º–µ—à–∏–≤–∞—Ç—å —Å—é–¥–∞:
                lora_url = info.get("url") if info else None
                img_bytes = generate_with_flux(face_bytes, prompt, lora_url=lora_url)

        await bot.send_photo(
            chat_id=uid,
            photo=BufferedInputFile(img_bytes, filename=f"{key}.jpg"),
            caption=f"–ì–æ—Ç–æ–≤–æ! –†–µ–∂–∏–º: {backend}  |  –°—Ç–∏–ª—å: {key}"
        )
    except Exception as e:
        logging.exception("Generation error")
        await cq.message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}\n–ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π —Å—Ç–∏–ª—å/—Ä–µ–∂–∏–º –∏–ª–∏ –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ.")

# ======== FINETUNE/LoRA FLOW ========
@dp.message(Command("train"))
async def cmd_train(m: Message):
    uid = m.from_user.id
    USER_TRAIN_SET[uid] = []
    USER_LORA.setdefault(uid, {"finetune_id": None, "trigger": None, "enabled": False, "status": "none"})
    await m.answer(
        "–ó–∞–≥—Ä—É–∑–∏ 6‚Äì12 —Ñ–æ—Ç–æ –∫–∞–∫ <b>—Ñ–∞–π–ª—ã</b> (—Å–∫—Ä–µ–ø–∫–∞ ‚Üí —Ñ–∞–π–ª). –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—à—å, –Ω–∞–ø–∏—à–∏ /finish.\n"
        "–°–æ–≤–µ—Ç—ã: —Ä–∞–∑–Ω—ã–µ —Ä–∞–∫—É—Ä—Å—ã, —Å–≤–µ—Ç, —ç–º–æ—Ü–∏–∏; –ª–∏—Ü–æ –∫—Ä—É–ø–Ω–æ; –±–µ–∑ —Ç—è–∂—ë–ª—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤."
    )

@dp.message(Command("finish"))
async def start_training(m: Message):
    uid = m.from_user.id
    imgs = USER_TRAIN_SET.get(uid, [])
    if len(imgs) < 6:
        return await m.answer("–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 6 —Ñ–æ—Ç–æ. –î–æ–∑–∞–≥—Ä—É–∑–∏ –∏ —Å–Ω–æ–≤–∞ /finish.")

    if not LORA_TRAINER_MODEL:
        return await m.answer(
            "‚ö†Ô∏è –¢—Ä–µ–Ω–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è LORA_TRAINER_MODEL –ø—É—Å—Ç–∞—è).\n"
            "–ó–∞–¥–∞–π –µ—ë –≤ Railway ‚Üí Variables (–ø—Ä–∏–º–µ—Ä: black-forest-labs/flux-pro-trainer) –∏ –ø–æ–≤—Ç–æ—Ä–∏."
        )

    USER_LORA[uid] = {"finetune_id": None, "trigger": None, "enabled": False, "status": "training"}
    await m.answer("üöÄ –ó–∞–ø—É—Å–∫–∞—é –æ–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–µ—Ç—é–Ω–∞‚Ä¶ –Ø –Ω–∞–ø–∏—à—É, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤–æ.")
    asyncio.create_task(_train_and_notify(uid, imgs))

@dp.message(Command("lora_on"))
async def lora_on(m: Message):
    uid = m.from_user.id
    info = USER_LORA.get(uid, {})
    # –≤–∫–ª—é—á–∞–µ–º –∏ –¥–ª—è finetune_id, –∏ –¥–ª—è url-–≤–∞—Ä–∏–∞–Ω—Ç–∞
    if not (info.get("finetune_id") or info.get("url")):
        return await m.answer("LoRA/finetune –µ—â—ë –Ω–µ –∑–∞–¥–∞–Ω. –°–Ω–∞—á–∞–ª–∞ /train –∏–ª–∏ /set_finetune <id>.")
    info["enabled"] = True
    info["status"] = info.get("status", "ready")
    USER_LORA[uid] = info
    await m.answer("LoRA/finetune –≤–∫–ª—é—á—ë–Ω ‚úÖ")

@dp.message(Command("lora_off"))
async def lora_off(m: Message):
    uid = m.from_user.id
    info = USER_LORA.get(uid, {})
    info["enabled"] = False
    USER_LORA[uid] = info
    await m.answer("LoRA/finetune –≤—ã–∫–ª—é—á–µ–Ω ‚õîÔ∏è")

@dp.message(Command("set_finetune"))
async def set_finetune(m: Message):
    uid = m.from_user.id
    parts = (m.text or "").split(maxsplit=1)
    if len(parts) < 2:
        return await m.answer("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /set_finetune &lt;finetune_id&gt;")
    fid = parts[1].strip()
    USER_LORA[uid] = {"finetune_id": fid, "trigger": f"user_{uid}", "enabled": True, "status": "ready"}
    await m.answer("‚úÖ finetune_id —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∏ –≤–∫–ª—é—á—ë–Ω. –†–µ–∂–∏–º FLUX ‚Üí /styles.")

# –°–æ–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç (–∫–∞–∫ —Ñ–∞–π–ª—ã)
@dp.message(F.content_type == ContentType.DOCUMENT, F.document.mime_type.in_({"image/jpeg","image/png"}))
async def collect_train_images(m: Message):
    uid = m.from_user.id
    if uid not in USER_TRAIN_SET:
        return  # –∏–≥–Ω–æ—Ä, –µ—Å–ª–∏ –Ω–µ /train
    b = await _download_as_bytes(m)
    USER_TRAIN_SET[uid].append(b)
    await m.answer(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–æ—Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç. –°–µ–π—á–∞—Å: {len(USER_TRAIN_SET[uid])} —à—Ç.")

# –§–æ–ª–±—ç–∫ (–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞)
@dp.message()
async def fallback(m: Message):
    txt = (m.text or m.caption or "").strip()
    await m.answer("–Ø –∑–¥–µ—Å—å üëã –ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ (–ª—É—á—à–µ –∫–∞–∫ —Ñ–∞–π–ª), –∑–∞—Ç–µ–º /styles. –†–µ–∂–∏–º—ã: /modes  |  –°–ø—Ä–∞–≤–∫–∞: /start")
    logging.info(f"Fallback update: content_type={m.content_type!r} text={txt!r}")

# ===================== MAIN =====================
async def main():
    logging.info("Starting bot polling‚Ä¶")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
